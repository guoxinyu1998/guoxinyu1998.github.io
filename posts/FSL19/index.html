<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners | Guo Xinyu's blog</title><meta name="keywords" content="🌌Machine Learning,🪐Meta-learning,📝Text Classification"><meta name="author" content="郭新宇"><meta name="copyright" content="郭新宇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="将文本输入转换为包含任务描述的完形填空，结合基于梯度的优化来实现和GPT-3相近的分类效果。">
<meta property="og:type" content="article">
<meta property="og:title" content="It&#39;s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners">
<meta property="og:url" content="https://gxystruggle.top/posts/FSL19/index.html">
<meta property="og:site_name" content="Guo Xinyu&#39;s blog">
<meta property="og:description" content="将文本输入转换为包含任务描述的完形填空，结合基于梯度的优化来实现和GPT-3相近的分类效果。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/37.jpg">
<meta property="article:published_time" content="2022-04-20T02:28:16.000Z">
<meta property="article:modified_time" content="2022-05-17T03:29:27.288Z">
<meta property="article:author" content="郭新宇">
<meta property="article:tag" content="🌌Machine Learning">
<meta property="article:tag" content="🪐Meta-learning">
<meta property="article:tag" content="📝Text Classification">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/37.jpg"><link rel="shortcut icon" href="/img/ironman.png"><link rel="canonical" href="https://gxystruggle.top/posts/FSL19/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="o966R8pi1rSGlykr"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#82284e"/><link rel="apple-touch-icon" sizes="180x180" href="/img/icons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/icons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/img/icons/favicon-16x16.png"/><link rel="mask-icon" href="/img/icons/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?65390daedf5e6542349db83925e31dbd";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":100},
  copy: {
    success: '我已经到了你的剪切板里，快去复制吧！',
    error: '你的剪切板有点难搞哦，复制失败了！',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 郭新宇","link":"链接: ","source":"来源: Guo Xinyu's blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'It\'s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-17 11:29:27'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css" /><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="gear-loader"><div class="gear-loader_overlay"></div><div class="gear-loader_cogs"><div class="gear-loader_cogs__top"><div class="gear-top_part"></div><div class="gear-top_part"></div><div class="gear-top_part"></div><div class="gear-top_hole"></div></div><div class="gear-loader_cogs__left"><div class="gear-left_part"></div><div class="gear-left_part"></div><div class="gear-left_part"></div><div class="gear-left_hole"></div></div><div class="gear-loader_cogs__bottom"><div class="gear-bottom_part"></div><div class="gear-bottom_part"></div><div class="gear-bottom_part"></div><div class="gear-bottom_hole"></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/%E5%A4%B4%E5%83%8F.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shouye"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shijianzhou"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian"></use></svg><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhinengduomeitiAPI"></use></svg><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-dianying"></use></svg><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuji"></use></svg><span> 书单</span></a></li><li><a class="site-page child" href="/music/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-box"></use></svg><span> 魔法盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo"></use></svg><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce"></use></svg><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wode"></use></svg><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/37.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Guo Xinyu's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shouye"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shijianzhou"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian"></use></svg><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhinengduomeitiAPI"></use></svg><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-dianying"></use></svg><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuji"></use></svg><span> 书单</span></a></li><li><a class="site-page child" href="/music/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-box"></use></svg><span> 魔法盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo"></use></svg><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce"></use></svg><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wode"></use></svg><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-04-20T02:28:16.000Z" title="发表于 2022-04-20 10:28:16">2022-04-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-17T03:29:27.288Z" title="更新于 2022-05-17 11:29:27">2022-05-17</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%F0%9F%93%9AFew-shot-Learning/">📚Few-shot Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>23分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><details class="folding-tag" ><summary> 论文相关信息，点击查看详情 </summary>
              <div class='content'>
              <p>2021年 </p><p>NAACL(The North American Chapter of the Association for Computational Linguistics)  </p><p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=MzIwMTc4ODE0Mw==&amp;mid=2247512167&amp;idx=1&amp;sn=cc7695d92362e3b18a6e8969fb14dc27&amp;chksm=96ea6fe7a19de6f1be86b965e268df1b9c6320810cf32b6d64ddd3d238bf9088be41fb36adfe&amp;scene=178&amp;cur_album_id=1507626217196322817#rd">论文解读1</a></p><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/375934846">论文解读2</a></p>
              </div>
            </details>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><ul>
<li><strong>GPT-3</strong>预训练语言模型在few-shot中达到了很好的性能，但涉及到的<strong>参数太多</strong>（千亿）。训练和使用这样的模型需要大量的计算。</li>
<li>有一种方法可以达到和GPT-3类似的性能，同时参数要小几个数量级。该方法<strong>通过将文本输入转换为包含任务描述的完形填空，结合基于梯度的优化来实现的</strong>。利用未标记的数据可以进行进一步的改进。</li>
<li>这是一个小型的语言模型，本文给出了用小型语言模型处理自然语言理解任务的关键因素。</li>
</ul>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>　　在大规模语料库上对越来越大的语言模型进行预处理，使自然语言处理任务取得了巨大进步。一个标准的方法是用一个task-specific head来替换预训练模型的输出层，并在一组标记的训练数据上微调整个模型。语言建模不仅是一个强有力的预训练目标，而且许多任务可以被重新表述为完形填空问题，可以让预训练语言模型在只有少量标记样本的情况下解决问题。</p>
<p>　　GPT-3是具有1750亿参数的预处理语言模型，有惊人的few-shot处理能力：通过将任务重构为语言建模问题，对于SuperGLUE(Wang et al.，2019)中的一些任务，在只有32个标记样本的情况下，GPT-3实现了接近最优的结果。这是通过<em>priming</em>实现的：给定GPT-3一些输入和相应的输出，作为其预测的上下文，但没有执行梯度更新。虽然使用起来很简单，但这种方法有两个主要的缺点:</p>
<ol>
<li><p>它需要一个巨大的语言模型才能正常工作，这使得它在许多现实场景中无法使用.</p>
</li>
<li><p>它不能扩展到样本较多的情况，因为大多数语言模型的上下文窗口被限制在几百个tokens内。</p>
</li>
</ol>
<p>　　<strong>进行<em>priming</em>的另一种方法是<em>pattern-explotiting training</em>(PET)</strong> ，<strong>它结合了将任务重新定义为完形填空题的想法和常规的基于梯度的微调</strong>。而<strong>PET需要额外的无标记数据</strong>，无标记数据比有标记数据更容易获得。至关重要的是，只有当语言模型预测的结果对应于其词汇表中的单个token时，PET才能工作；这是一个严重的限制，因为许多任务不能简单地这样描述。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_1.png" alt="FSL19_1"></p>
<p> 图1 </p>
<p>本文<strong>将PET用于需要预测多个token的任务</strong>。</p>
<p>与<strong>ALBERT</strong> 相结合的PET及其迭代变体(iPET)在SuperGLUE上的性能都优于GPT-3，而参数是GTP-3的0.1%(图1)。而且，PET在单个GPU上只需要几个小时就能训练出来，也不用进行超参数优化。</p>
<p>最后证明了在没有标签数据的情况下也可以实现类似的性能，并提供了对PET强大性能的因素的详细分析：它结合多个task formulations的能力，它对难以理解的词语的包容性，它对标签数据的使用，以及底层语言模型的特征。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><p>　　Radford et al.(2019)提出，通过提供任务描述可以使语言模型能够进行zero-shot learning，并已应用于文本分类。<strong>要想把任务重新组织成语言模型容易理解的完形填空题是很困难的</strong>。 Schick and Schütze (2021)提出了PET，<strong>一种使用知识蒸馏和self-training的方法，可以很容易的组合几个reformulations</strong>。本文修改后的PET使用了<strong>掩蔽(masked)语言模型</strong>来分配文本序列的概率。与使用了基于梯度优化的PET相反， Radford et al. (2019) and Brown et al. (2020)提出了<strong>priming</strong>,其中样本作为上下文给出，但不执行参数更新。</p>
<p>　　最后，本文关注于减少few-shot learning所需的计算量。</p>
<h3 id="Pattern-Exploiting-Training"><a href="#Pattern-Exploiting-Training" class="headerlink" title="Pattern-Exploiting Training"></a>Pattern-Exploiting Training</h3><p>　　$M$是一个掩蔽语言模型(MLM)，$T$是词汇表，$<em>{——} \in T$是掩码标记（token），把所有的token序列表示为$T^{\ast}$，对于$t \in T$以及至少包含k个掩码的$z \in T^{\ast}$，用$q</em>{M}^{k} (t|z)$表示在$z$中的第$k$个掩码位置处，$M$对其赋值为$t$的概率。模型在应用softmax之前的<strong>logits</strong> [1] 用$s<em>{M}^{k}(t|z)$表示。将输入$x \in X$映射为输出$y \in Y$，PET需要大量的<strong>pattern-verbalizer pairs</strong> (PVPs)集合。每个$PVP</em>{p} = (P,v)$包含:</p>
<ol>
<li><em>a pattern P</em>：$X \rightarrow T^{\ast}$，将输入映射为只包含一个掩码的完形填空问题。</li>
<li><em>a verbalizer v</em> : $Y \rightarrow T$将每个输出映射到表示模式中特定任务含义的单个标记。</li>
</ol>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_2.png" alt="FSL19_2"></p>
<p>图2 一个用于识别文本蕴含任务的PVP $p = (P,v)$，输入$x = (x<em>{1},x</em>{2})$被转变为完形填空问题$P(x)$；每个$y$的$q<em>{p}(y|x)$是根据掩蔽位置是$v</em>{y}$的概率推导出来的。</p>
<hr>
<p>　　如图2所示，<strong>PET的核心思想是，根据$P(x)$中掩蔽位置是$v(y)$的概率，推导出$y$是$x$的正确标签的概率。</strong>基于直观的认识，给定$x$，$y$的条件概率$q_{p}$是：</p>
<script type="math/tex; mode=display">
q_{p}(y|x) = \frac {exp s_{p}(y|x)}{\sum_{y^{'} \in Y}exps_{p}(y^{'}|x)}</script><p>公式1</p>
<p>其中，$s<em>{p}(y|x) = s</em>{M}^{1}(v(y)|P(x))$是$v(y)$在$P(x)$中掩码位置处的原始分数。</p>
<p>　　对于给定的任务，在缺乏大型开发集的情况下，找到表现良好的$PVPs$是一项挑战。因此，因此可以按照如下方式对多个$PVPs$ $P = {p<em>{1},…,p</em>{n}}$进行组合：</p>
<ol>
<li><p>对于每个$PVP$ p,通过最小化$y$和$q_{p}(y|x)$之间的交叉熵，在训练样本$(x,y)$上微调一个掩码语言模型(MLM)。在实践中，对于每个模式，Schick and Schütze(2021)训练了三个MLM，在运行时性能可能有很大差异。</p>
</li>
<li><p>微调的MLM的集合对未标记数据进行注释，对每个未标记的样本$x \in X$,根据概率分布用soft label 进行标注：</p>
<script type="math/tex; mode=display">
q_{\mathbf{P}}(y \mid x) \propto \exp \sum_{\mathbf{p} \in \mathbf{P}} w_{\mathbf{p}} \cdot s_{\mathbf{p}}(y \mid x)</script><p>公式2</p>
<p>和公式1类似，$w_{p}$是加权项，与训练前使用p在训练集上得到的精度成正比。</p>
</li>
<li><p>通过最小化输出和$q_{p}$之间的交叉熵，将得到的soft label标注的数据集用于训练常规的序列分类器。</p>
</li>
</ol>
<p>　　上述2、3步骤可以理解为蒸馏。重要的是，这个过程不需要同时在内存中保存整个MLM，因为每个模型的预测可以按顺序计算;因此，它并不比使用单一模型更消耗内存。</p>
<p>　　为给在不同模式上训练的MLMs提供进一步相互学习的机会, Schick<br>and Schütze (2021) 提出了iPET，这是PET的一个迭代变体，其中多代模型在由前几代标记的不断增长的数据集上进行训练。这是通过以下方式实现的：</p>
<ol>
<li>首先按照常规的PET方式训练得到一个MLMs的集合。</li>
<li>对于每个模型$M<em>{i}$，其他模型的一个随机子集通过给未标记的样本分配标签，得到一个新的训练集$T</em>{i}$，其中选择的模型子集对其预测具有最高置信度。</li>
<li>每个模型$M<em>{i}$在$T</em>{i}$上重新进行训练，这个过程重复几次，每次都将训练集$T_{i}$中的样本数量增大固定倍数。</li>
</ol>
<h4 id="PET-with-Multiple-Masks"><a href="#PET-with-Multiple-Masks" class="headerlink" title="PET with Multiple Masks"></a>PET with Multiple Masks</h4><p>　　<strong>PET的一个重要限制是，verbalizer v必须将每个输出映射到单个token</strong>，这对于多任务来说是不可能的。因此把verbalizers表示为函数$v\ :\ Y \rightarrow T^{\ast}$，这需要对推理和训练进行一些修改。我们进一步推广PET，即不假定每个输入的输出空间是相同的：对于每个$x \in X$，给定$x$作为输入时，本文用$Y<em>{x} \subseteq Y$表示<strong>可能的输出的集合</strong>。给定一个PVP p = (P,v)，我们定义$l(x) = max</em>{y \in Y<em>{x}}|v(y)|$为表示$Y</em>{x}$中任意输出所需的最大token数，$P^{k}(x)$表示$P(x)$中掩码位置被k个掩码所替代。</p>
<p>　　本文考虑了带有标签Y ={+1，−1}的餐馆评论的二元情感分类任务，使用模式$P(x) = x. It\ was\ _{——}$和一个verbalizer v，v将标签+1映射为单个token: <em>great</em>；将-1映射为<em>terri .ble</em>。假定MLM的分词器将“terrible”分割为“terri”和”.ble”。对于这个例子中的所有$x$，$l(x) = 2$，$P^{2}(x)$在图3（a）中进行了说明。</p>
<hr>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_3.png" alt="FSL19_3"></p>
<p>图3 由 terr 和 .ble两个token组成的词汇推理</p>
<ul>
<li>（a）：首先计算每个token在完形填空问题$P^{2}(x)$中所处位置的概率，并找出概率最高的token。</li>
<li>（b）：将这个token插入完形填空问题中，并计算剩余token的概率。</li>
</ul>
<hr>
<h5 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h5><p>　　对于$x\ \in X,\ y\ \in Y<em>{x}\ and\ |v(y)| = k$，以一种自回归的形式重新定义$q</em>{p}(y|x)$：从$P^{k}(x)$开始，执行k个连续的预测，根据MLM的置信度选择下一个token进行预测。也就是令$q_{p}(y|x) = q(v(y)|P^{k}(x))$，其中:</p>
<script type="math/tex; mode=display">
q\left(t_{1} \ldots t_{k} \mid \mathbf{z}\right)=\left\{\begin{array}{ll}
1 & \text { if } k=0 \\
q_{M}^{j}\left(t_{j} \mid \mathbf{z}\right) \cdot q\left(t^{\prime} \mid \mathbf{z}^{\prime}\right) & \text { if } k \geq 1
\end{array}\right.</script><p>公式3</p>
<p>$j\ =\ arg\ max<em>{i=1}^{k}q</em>{M}^{i}(t<em>{i}|\mathbf z)$，$\mathbf z^{‘}$是不包含$\mathbf z</em>{j}^{‘} = t<em>{j}$和$t^{‘} = t</em>{1}…t<em>{j-1}t</em>{j+1}…t<em>{k}$在内的$\mathbf z$。注意，与原始的PET  (公式 1)不同，$q</em>{p}$不是一个概率分布，它的值之和不是1。</p>
<p>　　对于情感分类例子，图3说明了$q_{p}(-1|x)$是如何计算的：$|v(y)| = |{terri,\cdot ble}|=2$，首先使用$\mathbf z = P^{2}(x)$计算$v(y)$中每个token的概率（图3a）。然后，我们选择概率最高的token，将其放在相应的掩码token处，并使用得到的完形填空问题$z^{\prime}$来计算剩余token的概率(图3b)。$y = -1$的总得分计算为：</p>
<script type="math/tex; mode=display">
q_{\mathbf{p}}(-1 \mid x)=q_{M}^{2}(\cdot \text { ble } \mid \mathbf{z}) \cdot q_{M}^{1}\left(\text { terri } \mid \mathbf{z}^{\prime}\right)</script><h5 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h5><p>　　对于每个训练样本$(x,y)$按照公式3的方法计算$q<em>{p}(y|x)$,这个过程代价很大。为了计算在一个向前传播过程中所需的所有概率，我们通过以下两种方式近似$q</em>{p}(y|x)$：</p>
<ol>
<li><p>总是插入表示任何输出所需的最大数量的掩码token</p>
</li>
<li><p>对于$y^{\prime} \in Y<em>{x}$，并行的预测$v(y^{\prime}) = t</em>{1},..t_{k}$中所有的token，我们简单的忽略模型对$l(x)-k$个多余的掩码token的预测：</p>
<script type="math/tex; mode=display">
\tilde{q}_{\mathbf{p}}\left(y^{\prime} \mid x\right)=\prod_{i=1}^{k} q_{M}^{i}\left(t_{i} \mid P^{l(x)}(x)\right)</script><p>公式4</p>
</li>
</ol>
<p>　　对于本文的例子，意味着可以通过计算</p>
<script type="math/tex; mode=display">
\begin{array}{l}
\tilde{q}_{\mathbf{p}}(+1 \mid x)=q_{M}^{1}(\text { great } \mid \mathbf{z}) \\
\tilde{q}_{\mathbf{p}}(-1 \mid x)=q_{M}^{1}(\text { terri } \mid \mathbf{z}) \cdot q_{M}^{2}(\cdot \text { ble } \mid \mathbf{z})
\end{array}</script><p>来近似分数$q_{p}(y|x)$，这可以在一个前向传递中完成，因为它只需要对图3（a）中的完形填空问题$\mathbf z = P^{2}(x)$处理一次。</p>
<p>　　由于$\tilde q<em>{p}$不是$Y</em>{x}$上的概率分布，交叉熵不是一个理想的训练目标，它也可以通过减少分配给不属于输出空间的序列$\mathbf z \notin v(Y_{x})$的概率来进行最小化,尽管这对模型的预测没有影响。本文使用<strong>多级铰链损失函数</strong>hinge loss，并且最小化：</p>
<script type="math/tex; mode=display">
\sum_{y^{\prime} \in Y_{x}} \max \left(0 ; 1-\log \tilde{q}_{\mathbf{p}}(y \mid x)+\log \tilde{q}_{\mathbf{p}}\left(y^{\prime} \mid x\right)\right)</script><p>公式5</p>
<p>也就是说，我们要求$y$的log概率和任何输出$y^{\prime} \in Y_{x} \setminus {y}$的log概率之差至少为1。</p>
<p>remark:</p>
<p>[1] :logits是指未归一化的值，即各个特征的加权之和，即softmax的输入</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><p>　　在SuperGLUE上比较了PET和GPT-3的性能，SuperGLUE是一个自然语言理解任务的benchmak。无法使用与GPT-3完全相同的训练数据来评估PET，因为对于大多数任务来说，GPT-3对每个测试样例使用不同的训练样本集，对于其他任务，需要的训练集不可用。然而，样本的准确选择对GPT-3的性能几乎没有影响（与GPT-3作者沟通得到）。因此，通过使用<strong>固定的随机seed</strong>[1]为每个任务随机选择32个样本来创建新的训练集。</p>
<p>　　我们还为每项任务创建了多达20，000个未标记样本的集合；这是通过从原始训练集中移除所有标签来完成的。我们将生成的训练样本集和未标记的样本集称为<strong>FewGLUE</strong>[2]。</p>
<p>remark:</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_41013470/article/details/82956178?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162485171316780255280538%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&amp;request_id=162485171316780255280538&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduend~default-2-82956178.first_rank_v2_pc_rank_v29_1&amp;utm_term=%E7%A7%8D%E5%AD%90seed&amp;spm=1018.2226.3001.4187">seed种子</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/timoschick/fewglue">数据集FewGLUE</a></p>
<h4 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h4><p>　　下面描述每个SuperGLUE任务和我们相应的PVP。使用竖线(|)来标记文本段之间的边界。在考虑的八项任务中，只有COPA、WSC和ReCoRD要求使用带多个掩码的PET（见章节PET with Multiple Masks）。</p>
<div class="tabs" id="task"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#task-1">BoolQ</button></li><li class="tab"><button type="button" data-href="#task-2">CB、RET</button></li><li class="tab"><button type="button" data-href="#task-3">WiC</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="task-1"><p><strong>BoolQ</strong> :QA问题  样本由文章p和一个是/否问题q组成。使用以下模式：</p>
<script type="math/tex; mode=display">
p.Question:q?Answer:_{——}.  \\
p.Based\ on\ the\ pervious\ passage,q?_{——}. \\
Based\ on\ the\ following\ passage,q?_{——}.p</script><p>在总共6个pvp中定义了两个verbalizers对问题进行映射，将一个正确的表述映射到yes/true，其他语句到no/false。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="task-2"><p><strong>CB、RET</strong>：文本蕴含任务，对于前提p和假设h,我们使用：</p>
<script type="math/tex; mode=display">
h?|_{——},p\ ,\ "h"?|_{——},"p"\ ,\ h?|_{——}.p\ ,\ "h"?|_{——}."p"</script><p>和一个verbalizer将蕴含映射为yes,不蕴含映射为no，可能映射为maybe</p>
<!--- endtab -->
<!-- tab COPA -->
<p><strong>COPA</strong>:对于给定的前提p，给定两个选项$c<em>{1}$和$c</em>{2}$，确定是前提p的原因还是结果。对于确定结果，使用以下模式：</p>
<script type="math/tex; mode=display">
"c_{1}"\ or "c_{2}"?\ p,so_{——}.\ ,\ c_{1}\ or\ c_{2}\ ?\ p,so_{——}.</script><p>对于确定原因，将so替换为Because即可。用于$c<em>{1}\ and\ c</em>{2}$的verbalizer是相同的。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="task-3"><p><strong>WiC</strong>：给定单词w和出现过w的句子$s<em>{1}\ and\ s</em>{2} $，任务是判断w在这两个句子中的意思是否相同。使用模式为:</p>
<script type="math/tex; mode=display">
\cdot "s_{1}/s_{2}".\ Similar\ sense\ of "w"?_{——}. \\
\cdot s_{1}\ s_{2}\ Does\ w\ have\ the\ same\ meaning\ in\ both\ sentences?_{——}  \\
\cdot w.Sense(1)(a)"s_{1}"(_{——})"s_{2}"</script><p>对于前两个模式，用yes表示具有相同意义的单词，no表示不同。对于第三个模式，使用b和2</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<h4 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h4><p>　　<strong>PET的底层语言模型为ALBERT-xxlarge-v2</strong>。当在常规、全部训练集上进行训练时，它是在SuperGLUE上表现最好的MLM。<strong>本文使用相同的模型，辅以序列分类头，作为最终的分类器</strong>。对于所有的SuperGLUE任务，在FewGLUE训练集上运行PET。不使用任何开发集来优化超参数;相反，使用与 Schick and Schütze (2021)完全相同的设置和超参数。对于COPA, WSC and ReCoRD，使用本文提出的改进的PET方法，支持verbalizers将标签映射为多个token。对于其他任务，使用常规的PET。在除COPA、WSC和ReCoRD之外的所有任务上训练iPET，因为COPA、WSC和ReCoRD的未标记集包含样本的数量远低于1000个，训练iPET没有意义，只使用单个PVP即可。对于这三个任务，只需重用常规PET的结果。</p>
<h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><p>　　主要结果如表1所示。带有ALBERT的PET的性能和大型的GPT-3模型的性能相当。PET和GPT-3 Med的模型大小相近，但是PET的平均性能比它高了18个点。在使用iPET的5个任务中，iPET为其中3个带来了进一步的改进，最显著的是CB，但对MultiRC造成了轻微的性能下降。尽管PET有强大的性能，它仍然明显比在常规，全尺寸SuperGLUE训练集上训练的最先进的模型性能更差。</p>
<hr>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_4.png" alt="FSL19_4"></p>
<p>表1：在常规方式、全尺寸设置下的SotA结果用斜体展示</p>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis　"></a>Analysis　</h3><p>研究了几个因素对few shot性能的重要性:</p>
<ul>
<li>模式和verbalizers的选择</li>
<li>未标记和标记数据的使用</li>
<li>底层语言模型的属性。</li>
</ul>
<p>还研究了提出的改进PET在多个masks情况下的效果，并将其与各种基线进行比较。</p>
<h4 id="Patterns"><a href="#Patterns" class="headerlink" title="Patterns"></a>Patterns</h4><p>　　<strong>任务被重新定义为完形填空的方式会对性能产生巨大的影响</strong>。这些重构可能是非常复杂的；例如，GPT-3中用于WSC的模式包含一个几乎有30个单词的介绍部分；尚不清楚这种构成是否可以被优化以及如何得到优化。为了研究patterns and verbalizers的重要性，对三种PVPs集合进行了比较：</p>
<ul>
<li>在Task里定义的初始集合($p_{ours}$)</li>
<li>GPT-3使用的单个PVP($p_{GPT-3}$)</li>
<li>将以上两种进行组合($p_{comb}$)</li>
</ul>
<p>　　用带有三种不同模式集合的PET训练ALBERT；得到的结果如表2(top)所示。可以看出来，GPT-3使用的PVP在RET上优于本文的PVPs，而本文方法的初始模式集合在MultiRC上表现更好。<strong>性能间的巨大差异表明将任务表示成完形填空问题的方法重要性</strong>。不在大量样本上进行尝试的话，很难知道哪个pattern性能更好，few-shot方法的一个关键挑战是对语言模型不能很好理解的PVPs进行补偿。$p<em>{comb}$训练的模型性能说明，PET可以做到这一点：合并所有的PVPs不仅补偿了$p</em>{ous}$在RET以及$p_{GTP-3}$在MultiRC上的较差性能，与性能最好的模式集相比，它甚至进一步提高了三项任务的平均性能。<strong>表明设计一个合适的模式集是非常有用的，单一模式不能评估有效性</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_5.png" alt="FSL19_5"></p>
<p>表2：对于常规PET和没有知识蒸馏($\urcorner dist$)的PET模型集合，不同PVP组的任务结果</p>
<h4 id="Unlabeled-Data-Usage"><a href="#Unlabeled-Data-Usage" class="headerlink" title="Unlabeled Data Usage"></a>Unlabeled Data Usage</h4><p>　　和GTP-3不同，<strong>PET需要使用未标记的数据将基于单个PVPs的所有模型的知识蒸馏到单个分类器中，对于iPET，未标记的数据还用于为下一代模型生成训练集</strong>。潜在的假设是未标记数据可以很容易获得，但在一些现实场景中未标记数据也不容易获得。因此，本文研究了<strong>常规PET中未标记数据的重要性</strong>。为此，将PET中<strong>最终分类器</strong>的性能与<strong>直接使用对应于单个PVPs的模型集合</strong>的性能进行了比较。虽然使用这种集成完全消除了对未标记数据的需求，但是k个PVPs的模型集合比蒸馏得到的模型大3k倍，我们遵循PET的默认设置，并且每个PVP训练三个模型。然而，即使是有很多的PVPs,集合的数量也比GTP-3小了两个数量级。</p>
<p>　　未蒸馏的结果见表2(bottom)。根据在三项任务上的平均性能，集合的性能比蒸馏得来的分类器性能更好。<strong>这说明如果目标只是为了达到良好的性能，那么无标签数据是不必要的；然而如果是为了获得一个单一的轻量模型作为最终分类器，无标签数据是需要的。</strong></p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_6.png" alt="FSL19_6"></p>
<p> 图4</p>
<p>图4展示了用iPET训练多代模型的好处。对于大多数任务，从第一代到第二代性能有明显提升，第三代仅仅实现了轻微的提升。平均而言，标准偏差在后代模型中降低，说明模型相互学习，预测趋同。最后的蒸馏步骤为除MultiRC之外的所有任务带来了进一步的改进，并将三次训练运行的标准偏差降低到几乎为零，说明PET和iPET是减小微调不稳定性的有效手段</p>
<p>　　当然，<strong>还有其他方法来利用未标记的数据，例如在微调期间利用辅助语言建模</strong>。</p>
<h4 id="Labeled-Data-Usage"><a href="#Labeled-Data-Usage" class="headerlink" title="Labeled Data Usage"></a>Labeled Data Usage</h4><p>　　研究标签数据的使用对结果的影响。这是<em>priming</em>和PET之间的一个关键区别。首先将PET与常规监督训练(不使用任何模式)，和完全无监督模型(使用所有PVPs的集合，但是没有标记训练样本)，给定32个样本，PET比这两个基线效果都好。</p>
<p>　　接下来直接比较PET和<em>priming</em>，但是，本文中的实验不能使用ALBERT，因为它只能处理最多512个tokens的序列，这对于32个样本是不够，于是使用XLNet 进行比较。XLNet的性能比ALBERT的性能普遍要差。更重要的是，带有PET的XLNet比<em>priming</em>性能更好。无法在MultiRC上使用<em>priming</em>来获得结果，因为在FewGLUE上，32个样本需要tokens的数量超过了10000个，由于self-attention的quadratic复杂度,使用标准的Transformer是不行的。这突出了<em>priming</em>的另一个问题：它不能扩展到样本较多的情况；甚至GPT-3也只能最多处理2048个token序列。而有些Transformer变体可以处理更长的上下文，这种模型在多大程度上能很好地利用长上下文范围内的<em>priming</em>样本还有待研究。</p>
<p>　　通过更密切地观察GPT-3获得的结果，进一步研究了<em>priming</em>的有效性。为此，对于不同的任务和模型大小，图5显示了用32个样本启动GPT-3和用单个样本启动GPT-3之间的性能差异。可以看出来，用32个样本启动的仅带来了轻微的性能提升。对于一些任务，添加更多的样本甚至导致了性能的下降，尤其是对于小模型而言。对于ReCoRD，当加入更多样本时，甚至连最大模型的性能都有明显的下降。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_7.png" alt="FSL19_7"></p>
<p>图5</p>
<p>　　图5的最后一行显示了用PET(没有蒸馏)训练的ALBERT和完全无监督的ALBERT模型在所有任务上的性能差异。虽然由于不同的底层模型和PVPs，结果不能直接比较，但与<em>priming</em>相比，PET形成更好的性能改善，并且不会恶化任何任务的结果。</p>
<h4 id="Model-Type"><a href="#Model-Type" class="headerlink" title="Model Type"></a>Model Type</h4><p>　　接下来通过将ALBERT与RoBERTa large和GPT-2 medium进行比较，研究潜在的LM对PET的影响。GPT-2是一个类似于GPT-3的单向模型，它只能处理mask token是最后一个token的模式。因此对CB和RTE使用$p_{GPT-3}$；对于MultiRC，使用最初的模式集，因为它们已经满足了需求。也不进行蒸馏，而是报告集合的性能，因为没有既定的方法为GPT-2配备序列分类头。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_8.png" alt="FSL19_8"></p>
<p>　　表4中用PET训练三个LMs的结果表明，<strong>使用ALBERT作为底层语言模型对于实现PET的强大性能是非常重要的</strong>；用RoBERTa替换ALBERT导致平均性能下降了8个点。然而，RoBERTa仍然优于GPT-3(GPT-3大两个数量级)。重要的是，PET搭配GPT-2的性能比搭配另外两种模型的性能都要差的多。Brown et al. (2020)推断，<strong>造成这种性能下降的原因可能是：像GPT-3，GPT-2都是单向的，使得需要比较两个序列的任务成为挑战</strong>。然而，需要注意的是，GPT-2和其他两个模型之间还有其他实质性的差异，最显著的是预训练数据集。不管单向性是否是GPT-2性能不佳的原因，<strong>底层LM的双向性对PET来说很重要，因为它消除了mask token必须在末尾处的条件，从而在创建模式时有更大的灵活性。</strong></p>
<h4 id="PET-with-Multiple-Masks-1"><a href="#PET-with-Multiple-Masks-1" class="headerlink" title="PET with Multiple Masks"></a>PET with Multiple Masks</h4><p>　　本文修改了PET，使其适用于需要不止一个token的输出。为了研究这种修改的影响，本文查看了三个需要这样做的任务:COPA、WSC和ReCoRD。将预测token的解码策略按照分配给它们的概率(我们称之为max-first)的顺序与两个备选方案进行比较:从左到右解码(ltr)，这在许多自回归语言模型中很常见;同时(并行)解码所有token。此外，本文将PET与未经训练的ALBERT进行比较，以衡量提出的训练损失的有效性。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_9.png" alt="FSL19_9"></p>
<p>　　结果如表5所示。在这三项任务上，PET明显优于未经训练的ALBERT。不进行蒸馏会影响COPA的性能，但会导致WSC略有改善；对于ReCoRD，没有在第一时间执行蒸馏，因为只使用一个单一的PVP。除了WSC之外，<strong>本文的解码策略明显优于并行解码</strong>（对于WSC，大多数预测只包含一个或两个tokens）<strong>并且比从左到右的解码性能稍好一些</strong>。</p>
<h4 id="Training-Examples"><a href="#Training-Examples" class="headerlink" title="Training Examples"></a>Training Examples</h4><p>　　FewGLUE是原始SuperGLUE训练示例的随机子集。使用固定的随机种子$s<em>{0}$来生成FewGLUE。设$\sum</em>{i}$是为随机种子$s<em>{i}$选择的SuperGLUE的随机子集，那么$\sum</em>{0}$ = FewGLUE。在本小节中，将基于不同的种子创建SuperGLUE的两个额外子集$\sum<em>{1}$and$\sum</em>{2}$。从而可以研究不同的训练样本是如何影响性能的。为此，本文将三种$\sum_{i}$用于CB、RTE和MultiRC的PET。为了只测量改变训练集对结果的影响，忽略未标记样本的影响，不使用蒸馏。</p>
<p>　　结果如表6所示，对于所有任务，改变训练样本集可以导致PET的巨大性能差异。这强调了在<strong>比较不同的few-shot方法时使用相同的一组样本的重要性</strong>。对于所有的seed，PET的平均性能与GPT-3接近。</p>
<p><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogimg/FSL19_10.png" alt="FSL19_10"></p>
<p>实验结果似乎与GPT-3的观点相反（样本的精确选择不重要），我们认为这是由于<em>priming</em>比PET从训练样本中获益要少的多，（即训练样本对于PET的影响更大），相应的，样本的选择对模型的性能影响较小（对于priming）。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li>对PET进行了简单而有效的改进，使其能够用于需要预测多个token的任务。</li>
<li>PET与ALBERT结合使用具有强大的性能，在广泛的实验中确定了影响性能的几个因素：同时使用多个模式将样本转换为完形填空题的可能性，对难以理解的模式进行补偿的能力，使用带标签的数据执行参数更新，以及底层LM本身。</li>
<li>证明用PET可以实现类似于SuperGLUE上GPT-3的few-shot文本分类性能，并且语言模型的参数少了三个数量级。</li>
</ul>
<p>未来工作中，可以研究以下问题：</p>
<ol>
<li>当PET与生成LM结合时，它是否也适用于生成任务</li>
<li><strong>在多任务设置中是否有可能进一步改进</strong></li>
</ol>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">郭新宇</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://gxystruggle.top/posts/FSL19/">https://gxystruggle.top/posts/FSL19/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://gxystruggle.top" target="_blank">Guo Xinyu's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%F0%9F%8C%8CMachine-Learning/">🌌Machine Learning</a><a class="post-meta__tags" href="/tags/%F0%9F%AA%90Meta-learning/">🪐Meta-learning</a><a class="post-meta__tags" href="/tags/%F0%9F%93%9DText-Classification/">📝Text Classification</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/37.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/jsandcss/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">好活儿，当赏！💰</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/wechat.png" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/zhifubao.png" target="_blank"><img class="post-qr-code-img" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/zhifubao.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer="defer" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/jsandcss/coin.js"></script><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/posts/FSL18/"><img class="next-cover" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/36.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Gitalk</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/%E5%A4%B4%E5%83%8F.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">郭新宇</div><div class="author-info__description">牧羊少年</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/guoxinyu1998" target="_blank" title="Github"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github1"></use></svg></a><a class="social-icon" href="mailto:984189011x@qq.com" target="_blank" title="Email"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-loveletter"></use></svg></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=984189011&amp;website=www.oicqzone.com" target="_blank" title="QQ"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-QQ"></use></svg></a><a class="social-icon" href="https://weibo.com/6079019133/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo" target="_blank" title="Weibo"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo1"></use></svg></a><a class="social-icon" href="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/blogbuild/微信名片.jpg" target="_blank" title="Wechat"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Related-Work"><span class="toc-number">3.</span> <span class="toc-text">Related Work</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pattern-Exploiting-Training"><span class="toc-number">4.</span> <span class="toc-text">Pattern-Exploiting Training</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PET-with-Multiple-Masks"><span class="toc-number">4.1.</span> <span class="toc-text">PET with Multiple Masks</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Inference"><span class="toc-number">4.1.1.</span> <span class="toc-text">Inference</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Training"><span class="toc-number">4.1.2.</span> <span class="toc-text">Training</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments"><span class="toc-number">5.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Tasks"><span class="toc-number">5.1.</span> <span class="toc-text">Tasks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Setup"><span class="toc-number">5.2.</span> <span class="toc-text">Setup</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Results"><span class="toc-number">5.3.</span> <span class="toc-text">Results</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Analysis"><span class="toc-number">6.</span> <span class="toc-text">Analysis　</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Patterns"><span class="toc-number">6.1.</span> <span class="toc-text">Patterns</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Unlabeled-Data-Usage"><span class="toc-number">6.2.</span> <span class="toc-text">Unlabeled Data Usage</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Labeled-Data-Usage"><span class="toc-number">6.3.</span> <span class="toc-text">Labeled Data Usage</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Model-Type"><span class="toc-number">6.4.</span> <span class="toc-text">Model Type</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#PET-with-Multiple-Masks-1"><span class="toc-number">6.5.</span> <span class="toc-text">PET with Multiple Masks</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Training-Examples"><span class="toc-number">6.6.</span> <span class="toc-text">Training Examples</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">7.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div><div class="card-widget card-recommend-post"><div class="item-headline"><i class="fas fa-dharmachakra"></i><span>相关推荐</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL12/" title="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c26.jpg" alt="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION"></a><div class="content"><a class="title" href="/posts/FSL12/" title="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION">ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION</a><time datetime="2022-03-19" title="发表于 2022-03-19">2022-03-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL10/" title="Dynamic Memory Induction Networks for Few-Shot Text Classification"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c24.jpg" alt="Dynamic Memory Induction Networks for Few-Shot Text Classification"></a><div class="content"><a class="title" href="/posts/FSL10/" title="Dynamic Memory Induction Networks for Few-Shot Text Classification">Dynamic Memory Induction Networks for Few-Shot Text Classification</a><time datetime="2022-03-05" title="发表于 2022-03-05">2022-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL14/" title="Few-Shot Learning with Global Class Representations"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c28.jpg" alt="Few-Shot Learning with Global Class Representations"></a><div class="content"><a class="title" href="/posts/FSL14/" title="Few-Shot Learning with Global Class Representations">Few-Shot Learning with Global Class Representations</a><time datetime="2022-03-27" title="发表于 2022-03-27">2022-03-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL2/" title="Few-shot learning for short text classification"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c13.jpg" alt="Few-shot learning for short text classification"></a><div class="content"><a class="title" href="/posts/FSL2/" title="Few-shot learning for short text classification">Few-shot learning for short text classification</a><time datetime="2022-01-08" title="发表于 2022-01-08">2022-01-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL8att2/" title="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c20.jpg" alt="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification"></a><div class="content"><a class="title" href="/posts/FSL8att2/" title="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification">Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification</a><time datetime="2022-02-23" title="发表于 2022-02-23">2022-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL6/" title="Diverse few-shot Text classification with multiple metrics"><img src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c18.jpg" alt="Diverse few-shot Text classification with multiple metrics"></a><div class="content"><a class="title" href="/posts/FSL6/" title="Diverse few-shot Text classification with multiple metrics">Diverse few-shot Text classification with multiple metrics</a><time datetime="2022-02-12" title="发表于 2022-02-12">2022-02-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022  <i id="heartbeat" class="fa fas fa-heartbeat"></i> 郭新宇</div></div><head><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/HCLonely/images@master/others/heartbeat.min.css"></head></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="to_comment" type="button" title="直达评论" onclick="FixedCommentBtn();"><i class="fas fa-comments"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-one-jade.vercel.app/',
      region: 'ap-baoding',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.vemoji)'))
      }
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo-one-jade.vercel.app/',
      region: 'ap-baoding',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      document.getElementById('twikoo-count').innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd72c334ea626f70aa6a5',
      clientSecret: 'd9b9e251acfdf70e336930214bdffe83f697e504',
      repo: 'gxystruggle_gitalk',
      owner: 'guoxinyu1998',
      admin: ['guoxinyu1998'],
      id: '95611deec4402cc9076c2bbf57c345b6',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://cdn.jsdelivr.net/npm/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Twikoo' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo-one-jade.vercel.app/',
        region: 'ap-baoding',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/jsandcss/fairyDustCursor.js"></script><script defer src="https://cdn.jsdelivr.net/npm/akilar-live2d-widget/autoload.min.js"></script><div class="aplayer no-destroy" data-id="2698841554" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="list" data-lrctype="1" data-preload="none" data-autoplay="false" muted></div><script async src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/jsandcss/dttitle.js"></script><script async src="//at.alicdn.com/t/font_3185678_5n830b5k2dm.js"></script><script data-pjax defer src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/jsandcss/fixed_comment.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="true"></script><script src="//code.tidio.co/m1tn6ajp5sxcxrsywtbtodb6ercpapyk.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#fixedcard-dashboard","#web_bg",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax], .pjax-reload script').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 郭新宇的魔法屋上新啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 郭新宇的魔法屋上新啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍭查看新品🍬',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><div id="ghbdages" style="overflow:hidden;max-height:90px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="http://beian.miit.gov.cn/" style="margin-inline:5px" title="本站已经成功在工信部备案"><img src="https://img.shields.io/badge/%E5%86%80ICP%E5%A4%87-2022002305%E5%8F%B7-e1d492?style=plastic&amp;logo=data:image/png;base64,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" alt=""/></a><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.0.0"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=plastic&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.0.1"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=plastic&amp;logo=bitdefender" alt=""/></a></div><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站资源托管在Github"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=plastic&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站由Vercel提供加速服务"><img src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=plastic&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init.min.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/11/" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c11.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-25</span><a class="blog-slider__title" href="posts/11/" alt="">C++感悟</a><div class="blog-slider__text">C++自学思路指南以及心得体会！</div><a class="blog-slider__button" href="posts/11/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/10/" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c10.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-24</span><a class="blog-slider__title" href="posts/10/" alt="">Few-shot Learning</a><div class="blog-slider__text">FSL相关论文以及个人理解！</div><a class="blog-slider__button" href="posts/10/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ynzz1/" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c9.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-24</span><a class="blog-slider__title" href="posts/ynzz1/" alt="">20年老中医，专治各种疑难杂症</a><div class="blog-slider__text">记录一下学习生活中遇到的各种稀奇古怪的难题！</div><a class="blog-slider__button" href="posts/ynzz1/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/6/" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c8.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-22</span><a class="blog-slider__title" href="posts/6/" alt="">如何写出令人赏心悦目的博客</a><div class="blog-slider__text">markdown命令，latex数学符号，博客中的图片问题，外挂标签的使用……想要写出清晰明了，美观大气的博客看这一篇就够了！</div><a class="blog-slider__button" href="posts/6/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/1/" alt=""><img width="48" height="48" src="https://cdn.jsdelivr.net/gh/guoxinyu1998/blogimg1/backandcover/c4.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-02-15</span><a class="blog-slider__title" href="posts/1/" alt="">Hexo和Butterfly那点事儿</a><div class="blog-slider__text">Hexo博客搭建、Butterfly主题美化以及个性化设置！</div><a class="blog-slider__button" href="posts/1/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0.5s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://blog-calendaler.vercel.app/api?guoxinyu1998",['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06'],'guoxinyu1998')
    }
  </script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>