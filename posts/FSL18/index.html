<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference | Guo Xinyu's blog</title><meta name="keywords" content="🌌Machine Learning,🪐Meta-learning,📝Text Classification"><meta name="author" content="郭新宇"><meta name="copyright" content="郭新宇"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="提出了PET训练模式，以完形填空的方式解决FSL问题。">
<meta property="og:type" content="article">
<meta property="og:title" content="Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference">
<meta property="og:url" content="https://gxystruggle.top/posts/FSL18/index.html">
<meta property="og:site_name" content="Guo Xinyu&#39;s blog">
<meta property="og:description" content="提出了PET训练模式，以完形填空的方式解决FSL问题。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://npm.elemecdn.com/gxy-assets/backandcover/34.jpg">
<meta property="article:published_time" content="2022-04-17T01:20:15.000Z">
<meta property="article:modified_time" content="2022-05-18T12:32:30.316Z">
<meta property="article:author" content="郭新宇">
<meta property="article:tag" content="🌌Machine Learning">
<meta property="article:tag" content="🪐Meta-learning">
<meta property="article:tag" content="📝Text Classification">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://npm.elemecdn.com/gxy-assets/backandcover/34.jpg"><link rel="shortcut icon" href="https://npm.elemecdn.com/gxy-assets/blogbuild/ironman.png"><link rel="canonical" href="https://gxystruggle.top/posts/FSL18/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//hm.baidu.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="o966R8pi1rSGlykr"/><link rel="manifest" href="/manifest.json"/><meta name="msapplication-TileColor" content="#82284e"/><link rel="apple-touch-icon" sizes="180x180" href="/img/icons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/img/icons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/img/icons/favicon-16x16.png"/><link rel="mask-icon" href="/img/icons/safari-pinned-tab.svg" color="#5bbad5"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://npm.elemecdn.com/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?65390daedf5e6542349db83925e31dbd";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: {"limitDay":365,"position":"top","messagePrev":"It has been","messageNext":"days since the last update, the content of the article may be outdated."},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":100},
  copy: {
    success: '我已经到了你的剪切板里，快去复制吧！',
    error: '你的剪切板有点难搞哦，复制失败了！',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: 郭新宇","link":"链接: ","source":"来源: Guo Xinyu's blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'mediumZoom',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#121212","position":"bottom-left"},
  source: {
    justifiedGallery: {
      js: 'https://npm.elemecdn.com/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://npm.elemecdn.com/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-05-18 20:32:30'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.css" /><link rel="stylesheet" href="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/animate.min.css" media="print" onload="this.media='screen'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-footer-beautify@1.0.0/lib/runtime.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/font-awesome-animation.min.css" media="defer" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/tag_plugins.css" media="defer" onload="this.media='all'"><script src="https://npm.elemecdn.com/hexo-butterfly-tag-plugins-plus@latest/lib/assets/carousel-touch.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.0.0"></head><body><div id="loading-box"><div class="gear-loader"><div class="gear-loader_overlay"></div><div class="gear-loader_cogs"><div class="gear-loader_cogs__top"><div class="gear-top_part"></div><div class="gear-top_part"></div><div class="gear-top_part"></div><div class="gear-top_hole"></div></div><div class="gear-loader_cogs__left"><div class="gear-left_part"></div><div class="gear-left_part"></div><div class="gear-left_part"></div><div class="gear-left_hole"></div></div><div class="gear-loader_cogs__bottom"><div class="gear-bottom_part"></div><div class="gear-bottom_part"></div><div class="gear-bottom_part"></div><div class="gear-bottom_hole"></div></div></div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://npm.elemecdn.com/gxy-assets/blogbuild/%E5%A4%B4%E5%83%8F.jpg" onerror="onerror=null;src='https://npm.elemecdn.com/gxy-assets/blogbuild/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shouye"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shijianzhou"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian"></use></svg><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhinengduomeitiAPI"></use></svg><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-dianying"></use></svg><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuji"></use></svg><span> 书单</span></a></li><li><a class="site-page child" href="/music/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-box"></use></svg><span> 魔法盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo"></use></svg><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce"></use></svg><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wode"></use></svg><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://npm.elemecdn.com/gxy-assets/backandcover/34.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Guo Xinyu's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shouye"></use></svg><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shijianzhou"></use></svg><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-biaoqian"></use></svg><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-fenlei"></use></svg><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-zhinengduomeitiAPI"></use></svg><span> 生活</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/movies/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-dianying"></use></svg><span> 电影</span></a></li><li><a class="site-page child" href="/books/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuji"></use></svg><span> 书单</span></a></li><li><a class="site-page child" href="/music/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-yinle"></use></svg><span> 音乐</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/box/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-box"></use></svg><span> 魔法盒</span></a></div><div class="menus_item"><a class="site-page" href="/talk/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-shuoshuo"></use></svg><span> 说说</span></a></div><div class="menus_item"><a class="site-page" href="/gallery/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-xiangce"></use></svg><span> 相册</span></a></div><div class="menus_item"><a class="site-page" href="/contact/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-liuyanban"></use></svg><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wode"></use></svg><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-04-17T01:20:15.000Z" title="发表于 2022-04-17 09:20:15">2022-04-17</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-05-18T12:32:30.316Z" title="更新于 2022-05-18 20:32:30">2022-05-18</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%F0%9F%93%9AFew-shot-Learning/">📚Few-shot Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">6.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>22分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>2021年   EACL（欧洲人工智能会议）</p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/375934846">论文解读</a></p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2001.07676.pdf">论文地址</a></p>
<h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>　　一些自然语言处理任务可以通过用自然语言中<strong>具有“任务描述”的预训练语言模型，以完全无监督的方式来解决</strong>(例如，Radford et al.，2019)。虽然这种方法的性能不如监督学习，但我们在这项工作中表明，<strong>这两种思想可以结合起来：本文引入了Pattern-Exploiting Training (PET)，这是一种半监督的训练过程，将输入的样本重新表述为完形填空式短语，以帮助语言模型理解给定的任务</strong>。然后，这些<strong>短语被用来给大量未标记的样本分配soft标签</strong>。最后，<strong>对得到的训练集进行标准的监督训练</strong>。对于多种任务和语言，<strong>在低资源环境下，PET比监督训练和强化半监督训练方法的性能好很多</strong>。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>　　从样本中学习是许多自然语言处理任务的主要方法:在一组带标记的样本上训练模型，然后泛化到unseen数据。由于语言、领域和任务的数量很大，以及标记数据的成本，在自然语言处理的实际应用中，只有少量的标记样本是很常见的，这使得few-shot学习成为一个非常重要的研究领域。但将标准监督学习应用于小的训练集通常表现不佳；仅有几个样本很难解决问题。例如以下几段文字:</p>
<p>T1: This was the best pizza I’ve ever had.<br>T2: You can get better sushi for half the <strong>price</strong>.<br>T3: Pizza was average. Not worth the <strong>price</strong>.</p>
<p>　　此外，假设$T<em>{1}$和$T</em>{2}$的标签分别是$l$和$l^{‘}$，要求对$T<em>{3}$的标签进行预测。仅基于这两个样本，是不可能的。然而，如果知道潜在的任务是识别文本中是否有关于prices的内容，可以很容易地将标签$l^{‘}$分配给$T</em>{3}$。这说明，当我们有一个task description，即一个帮助我们理解任务的文本解释时，仅从几个样本中解决任务变得容易得多。</p>
<p>　　随着<strong>GTP</strong>(Radford et al.，2018)[1]、BERT  (Devlin et al.，2019)[2]和RoBERTa(liu et al，2019)[3]等<strong>预训练语言模型(PLMs)</strong>的兴起，提供task descriptions的想法对于神经架构变得可行：可以简单地用自然语言将这些描述添加到输入中，让PLM解决后续任务。到目前为止，这个想法主要是在完全没有训练数据的zero-shot场景下考虑的。</p>
<hr>
<p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_1.png" alt="FSL18_1"></p>
<details class="folding-tag" ><summary> 图1，PET用于情感分类，点击查看详细说明 </summary>
              <div class='content'>
              <p>(1)创建了许多patterns,这些patterns编码一些形式的任务描述，以将训练样本转换为完形填空问题；对于每个pattern，预训练语言模型都会被微调。</p><p>(2)训练模型的集合对未标记的数据进行注释</p><p>(3)在得到的soft-labeled数据集上训练分类器。</p>
              </div>
            </details>
<p>　　提供<strong>任务描述可以成功地与标准的监督学习结合在一起</strong>：本文提出了 <strong>Pattern-Exploiting Training (PET)</strong>，这是一种<strong>半监督</strong>的训练过程，使用<strong>自然语言模式将输入样本重新表述为完形填空式短语</strong>。如图1所示，PET 分三步进行:</p>
<ol>
<li><strong>首先，对于每个pattern，一个单独的PET在一个小的训练集$\mathcal T$上进行微调。</strong></li>
<li><strong>然后，用所有的模型将一个大的未标记数据集注释为soft label。</strong></li>
<li><strong>最后，在soft label标注的数据集上训练标准分类器。我们还设计了iPET，PET的一种迭代变体，其中这个过程随着训练集大小的增加而重复</strong>。</li>
</ol>
<p>　　在多种语言的不同任务集上，我们表明<strong>给定少量到中等数量的标记样本，PET和iPET显著优于无监督方法、有监督训练和强化半监督基线</strong>。</p>
<h3 id="Pattern-Exploiting-Training"><a href="#Pattern-Exploiting-Training" class="headerlink" title="Pattern-Exploiting Training"></a>Pattern-Exploiting Training</h3><p>　　设$M$是一个带有词汇$V$和mask tokens<em> </em> <em> </em>$\in V$的掩蔽语言模型，设$\mathcal L$是目标分类任务A的一组标签，把任务$A$的输入表示为短语序列：</p>
<p>$x = (s<em>{1},…,s</em>{k})，s_{i} \in V^{*}$</p>
<p>　　例如，如果A是文本推理(两个输入句子)，k =  2。<strong>把一个<em>pattern</em>定义为一个函数P</strong>，它<strong>以x为输入，输出一个恰好包含一个mask token的短语或句子$P(x) \in V^{*}$</strong>，<strong>它的输出可以看作是一个完形填空问题</strong>。此外，<strong>将<em>verbalizer</em>定义为 injective function   $v: \mathcal L \rightarrow V$，它将每个标签映射到M词汇表中的一个单词</strong>。称$(P,v)$为 <strong>pattern-verbalizer pair (PVP)</strong>。</p>
<p>remark：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/magicdoubi/article/details/109435222?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162415421716780357254867%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=162415421716780357254867&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-109435222.pc_search_result_cache&amp;utm_term=injective&amp;spm=1018.2226.3001.4187">injective function</a></p>
<p>使用PVP (P，v)使我们能够按照如下方式解决任务A：</p>
<p>　　<strong>给定一个输入x，应用$P$得到一个输入表示$P(x)$，然后由$M$来确定标签$y$，其中$v(y)$是mask的最有可能的替代者</strong>（假设标签$l$对应的单词在mask位置最有可能出现，该输入的标签就$l$）。例如，考虑确定两个句子a和b是否相互矛盾(标记为$y<em>{0}$)或相互一致(标记为$y</em>{1}$)，对于这个任务，我们可以选择模式$P(a, b)=a ?<em>{- - - -}, b$与verbalizer $v$组合使用，将$y</em>{0}$映射为“Yes”，将$y_{0}$映射为“No”(标签映射为单词)。给定一个样本输入对：</p>
<p>x  = (Mia likes pie,Mia hates pie)，</p>
<p>现在的任务从分配一个没有内在意义的标签变成了回答masked位置的最有可能的选择是”Yes”还是”No”。</p>
<p>P(x) = Mia likes pie? <em> </em> <em> </em>,Mia hates pie.</p>
<h4 id="PVP-Training-and-Inference"><a href="#PVP-Training-and-Inference" class="headerlink" title="PVP Training and Inference"></a>PVP Training and Inference</h4><p>　　设$p = (P,v)$是一个PVP,我们假设有一个小的训练集$\mathcal T$和一个未标记样本集$D$(通常大得多)。对于只包含一个mask token的序列$z \in V^{\ast}$和$w \in V$($w$是标签对应的单词),<strong>用$M(w|z)$表示语言模型分配给$w$在masked位置的非标准化分数</strong>。给定输入$x$,将标签$l \in  \mathcal L$的分数定义为:</p>
<script type="math/tex; mode=display">
s_{p}(l,x) = M(v(l)|P(x))</script><p>（ $M(v(l)|P(x))$怎么计算呢？）</p>
<p>用softmax得到标签的概率分布：</p>
<script type="math/tex; mode=display">
q_{p}(l|x) = \frac{e^{s_{p}(l|x)}}{\sum_{l^{'}\in L}e^{s_{p}(l^{'}|x)}}</script><p>　　<strong>使用$q_{p}(l|x)$和训练样本$(x.l)$的真实(one-hot)分布之间的交叉熵</strong>——在所有$(x,l) \in \mathcal T$上求和——作为对于p微调M的损失函数。</p>
<h4 id="辅助语言建模"><a href="#辅助语言建模" class="headerlink" title="辅助语言建模"></a>辅助语言建模</h4><p>　　在本文的应用场景中，只有几个训练样本可用，并且会发生灾难性的遗忘。由于为某些PVP微调的PLM的核心仍然是语言模型，所以通过使用<strong>语言建模</strong>作为辅助任务来解决这个问题。用$L<em>{CE}$表示交叉熵损失,$L</em>{MLM}$表示<strong>语言建模损失</strong>，计算最终损失：</p>
<script type="math/tex; mode=display">
L = (1- \alpha) \cdot L_{CE} + \alpha \cdot L_{MLM}</script><p>　　Chronopoulou et al.(2019)最近在一个数据丰富的场景中应用了这个想法。由于$L<em>{MLM}$通常比$L</em>{CE}$大得多，在初步实验中发现$\alpha = 10^{-4}$时的结果较好，因此本文在所有实验中都使用这个值。</p>
<p>　　为了获得用于语言建模的句子，本文使用未标记的集合D。然而，不是直接在每个$x \in D$上训练，而是在P(x)上训练，在P(x)上，不用语言模型对masked位置进行任何预测。</p>
<h4 id="Combining-PVPs"><a href="#Combining-PVPs" class="headerlink" title="Combining PVPs"></a>Combining PVPs</h4><p>　　本文方法面临的一个关键挑战是，在没有大型开发集的情况下，很<strong>难确定哪些PVP表现良好</strong>。为了解决这个问题，本文使用了类似于<strong>知识蒸馏</strong>的策略。首先定义一个对给定任务$A$有直观意义的PVPs的集合$P$。然后按照如下方式使用这些PVP:</p>
<ol>
<li><p><strong>我们为每个$p \in P$微调一个单独的语言模型$M_{p}$。由于训练集$\mathcal T$很小，即使PVPs的数量很多，这种微调代价也很小。</strong></p>
</li>
<li><p><strong>我们使用微调模型的集合$\mathcal M = {M_{p}|p \in P }$来注释D中的样本。我们首先将D中的每个样本x的非标准化类别分数组合为：</strong></p>
<script type="math/tex; mode=display">
s_{\mathcal{M}}(l \mid \mathbf{x})=\frac{1}{Z} \sum_{\mathbf{p} \in \mathcal{P}} w(\mathbf{p}) \cdot s_{\mathbf{p}}(l \mid \mathbf{x})</script><p>$Z = \sum_{p \in P}w(p)$和$w(p)$是用于PVPs的加权项。本文对这个加权项的两种不同实现方式进行了实验：要么<strong>简单地为所有p设置</strong>$w(p) = 1$，<strong>要么将$w(p)$设置为在训练前使用$p$在训练集上获得的精度</strong>。这两个方法分别被称为为<strong>uniform和weighted</strong>。</p>
<p>使用softmax将上述分数转换为概率分布$q$。使用T =  2的temperature 来获得合适的soft分布。所有的pairs$(x,q)$都在一个(soft-labeled)训练集$\mathcal T_{C}$中。</p>
</li>
<li><p><strong>用一个标准的序列分类head在$\mathcal T_{C}$上微调一个PLM ,记作 $C$</strong></p>
</li>
</ol>
<p>　　<strong>微调后的模型C作为用于A的分类器</strong>。上面的所有步骤都在图2中描述；图1显示了一个例子。</p>
<hr>
<p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_2.png" alt="FSL18_2"></p>
<details class="folding-tag" ><summary> 图2，PET（1-3）和iPET（a-c）的图解表示 </summary>
              <div class='content'>
              <p>（1）初始训练集用于微调一组PLMs</p><p>（a）对于每个模型，其他的一部分模型通过标记$\mathcal D$中的样本来生成新的训练集。</p><p>（b）使用更大的、特定于模型的数据集来训练一组新的PET模型。</p><p>（c）前面的两个步骤重复k次，每次将生成的训练集的大小增加d倍。</p><p>（2）最后一组模型用于创建soft-labeled数据集</p><p>（3）在这个数据集上训练一个分类器</p>
              </div>
            </details>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/nature553863/article/details/80568658?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162415735116780271532177%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fall.%2522%257D&amp;request_id=162415735116780271532177&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_v2~rank_v29-1-80568658.pc_search_result_cache&amp;utm_term=knowledge+distillation&amp;spm=1018.2226.3001.4187">knowledge distillation 知识蒸馏</a></p>
<h4 id="Iterative-PET-iPET"><a href="#Iterative-PET-iPET" class="headerlink" title="Iterative PET (iPET)"></a>Iterative PET (iPET)</h4><p>　　将所有单个模型的知识提取到单个分类器$C$中意味着它们不能相互学习。由于一些模式比其他模式表现差(可能差得多)，因此用于最终模型的训练集$\mathcal T_{C}$可能包含许多错误标记的样本。</p>
<p>　　为了弥补这个缺点，本文又设计了iPET，这是PET的一个迭代变体。<strong>iPET的核心思想是在越来越大的数据集上训练多代模型。</strong>首先通过使用训练好的PET模型的随机子集对从D中的样本进行标记来扩大原始数据集$\mathcal T$(图2a)。然后在增大的数据集上训练新一代的PET模型(b)；这个过程重复多次(c)。</p>
<p>　更具体一些就是，<strong>设$\mathcal M^{0} = {M<em>{1}^{0},…,M</em>{n}^{0} }$是在$\mathcal T$上微调的PET模型的初始集合，每个$M<em>{i}^{0}$被训练后，用于PVP$p</em>{i}$。我们训练k代模型$\mathcal M^{1} ,…,\mathcal M^{k}$，其中$\mathcal M^{j} = {M<em>{1}^{j},…,M</em>{n}^{j} }$，每个$M<em>{i}^{j}$在它自己的训练集$\mathcal T</em>{i}^{j}$上进行训练，用于$p<em>{i}$。在每次迭代中将训练集的大小乘以一个固定的常数$d \in N$，同时保持原始数据集的标签比率。也就是说，$c</em>{0}(l)$表示在$\mathcal T$中标签为$l$的样本的数量，$\mathcal T<em>{i}^{j}$中包含$c</em>{j}(l) = d \cdot c<em>{j-1}(l)$个标签为$l$的样本，$\mathcal T</em>{i}^{j}$的生成方式如下</strong>：</p>
<ol>
<li><p>从上一代随机选择λ·(N−1)个PET模型，λ∈(0,1]是一个超参数，从而得到$\mathcal N$，$\mathcal N \subset \mathcal M^{j-1} \setminus {M_{i}^{j-1}}$。</p>
</li>
<li><p>使用选择的PET模型，创建一个带标签的数据集:</p>
<script type="math/tex; mode=display">
\mathcal{T}_{\mathcal{N}}=\left\{\left(\mathbf{x}, \arg \max _{l \in \mathcal{L}} s_{\mathcal{N}}(l \mid \mathbf{x})\right) \mid \mathbf{x} \in \mathcal{D}\right\}</script><p><strong>对于每个$l \in  \mathcal L$，通过从$\mathcal T<em>{\mathcal N}$中随机选择$c</em>{j}(l)-c_{0}(l)$个标签为$l$的样本</strong>。为了避免用错误标签的数据来训练下一代模型，更倾向于PET模型能够准确预测的样本。其中的思想是，即使没有校准，<strong>如果对某个样本预测的标签具有高置信度，这个样本通常更有可能被正确分类</strong>。因此，当从$\mathcal T<em>{\mathcal N}$中提取时，设置每个$(x,y)$的概率与$s</em>{\mathcal{N}}(l \mid \mathbf{x})$成比例。</p>
</li>
<li><p>定义$\mathcal{T}<em>{i}^{j}=\mathcal{T} \cup \bigcup</em>{l \in \mathcal{L}} \mathcal{T}<em>{\mathcal{N}}(l)$。很容易验证，对于$\mathcal L$中的每个标签$l$，这个数据集中包含$c</em>{j}(l)$个样本。</p>
</li>
</ol>
<p>　　在训练了k代PET模型后，我们使用$\mathcal M<em>{k}$创建$\mathcal   T</em>{C}$，并且训练$C$，就像在基础PET中一样。</p>
<p>　　稍加调整，iPET甚至可以用于zero-shot设置。为此，我们将$M^{0}$定义为未训练模型的集合，并且对于所有$l \in \mathcal L$，$c<em>{1}(l) = 10 \setminus |\mathcal L|$,因此$M^{1}$在10个样本上训练，这些样本均匀分布在所有标签上。由于$\mathcal T</em>{\mathcal N}$中某些标签为$l$的样本可能不够多，我们通过从$s<em>{\mathcal N}(l|x)$最高的100个样本($x \in D$)中采样来创建所有$\mathcal T</em>{\mathcal N}(l)$，即使$l \neq argmax<em>{l \in \mathcal L}s</em>{\mathcal N}(l|x)$。随后的每一代模型，处理的方式和基本的iPET一样。</p>
<h3 id="Experiments"><a href="#Experiments" class="headerlink" title="Experiments"></a>Experiments</h3><ul>
<li>在四个英文数据集上评估PET:Yelp  Reviews，AG’s News，Yahoo Questions和MNLI。</li>
<li>此外，使用x-stance来研究PET对其他语言的效果。对于所有关于英语的实验，使用RoBERTa  large作为语言模型；对于x-stance，使用。</li>
<li>调查了在不同训练集大小上的PET和所有基线的性能；每个模型使用不同的seeds训练三次，取平均结果。</li>
</ul>
<p>　　当考虑few-shot设置时，假设没有大型开发集，超参数不能被优化。因此，对超参数的选择是基于以前工作中的选择和实际考虑。</p>
<details class="folding-tag" ><summary> 详细超参数设置 </summary>
              <div class='content'>
              <p>我们使用的学习率为$10^{-5}$，batch size为16，最大序列长度为256。除非另有说明，我们总是使用带辅助语言建模的PET的加权变体。对于iPET，我们设置λ  = 0.25（选择PET模型时需要用到），d =  5（数据集扩大的比例）；也就是说，<strong>我们选择25%的PET模型来标记用于下一代PET的样本，并且在每次迭代中将训练样本的数量增加五倍</strong>。我们<strong>训练新一代PET，直到每个模型至少在1000个样本上进行了训练</strong>，我们设$k=\left\lceil\log _{d}(1000 /|\mathcal{T}|)\right\rceil$。由于我们总是重复训练三次，n个PVPs的所有$\mathcal M$包含3n个PET模型。超参数的选择和详细解释见附录B。</p>
              </div>
            </details>
<h4 id="Patterns"><a href="#Patterns" class="headerlink" title="Patterns"></a>Patterns</h4><p>描述用于所有任务的patterns和verbalizers。使用两个竖线(||)来标记文本段之间的边界。</p>
<div class="tabs" id="pattern"><ul class="nav-tabs"><li class="tab active"><button type="button" data-href="#pattern-1">Yelp</button></li><li class="tab"><button type="button" data-href="#pattern-2">AG's News</button></li><li class="tab"><button type="button" data-href="#pattern-3">MNLI</button></li><li class="tab"><button type="button" data-href="#pattern-4">X-Stance</button></li></ul><div class="tab-contents"><div class="tab-item-content active" id="pattern-1"><p><strong>Yelp</strong>  对于Yelp Reviews Full Star dataset，任务是根据点评文本，在1到5星级的范围内评估顾客对餐厅的评分。我们为输入文本a定义了以下patterns:</p>
<script type="math/tex; mode=display">
P_{1}(a) = It\ was\ _{----}.\ a          \\
P_{2}(a) =Just\ _{----}!\ ||\ a          \\
P_{3}(a) = a.\ All\ in\ all, it\ was\ _{----}.   \\
P_{4}(a) = a\ ||\ In\ summary\ ,the\ restaurant\ is\ _{----}.</script><p>我们为所有patterns定义了一个单独的verbalizers v：</p>
<script type="math/tex; mode=display">
v_{1} = terrible  \\
v_{2} = bad \\
v_{3} = okay \\
v_{4} = good \\
v_{5} = great</script><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="pattern-2"><p><strong>AG’s News</strong>  AG’s  News是一个新闻分类数据集，其中给定标题a和正文b，新闻必须被分类为World (1), Sports (2), Business (3) or Science/Tech (4)。对于x =  (a，b)，我们定义以下patterns：</p>
<p>$P<em>{1}(x)$ = </em> <em> </em> _: a b                 </p>
<p>$P<em>{2}(x)$ = a(</em> <em> </em> _)b</p>
<p>…… = <em> </em> <em> </em>—-a b</p>
<p>…… = a b(<em> </em> <em> </em>)</p>
<p>…… = <em> </em> _ _News: a b</p>
<p>…… = [Category:<em> </em> <em> </em>] a b</p>
<p>使用一个verbalizer,把1-4的标签分别映射为“World”, “Sports”, “Business” and “Tech”</p>
<!-- endtab --->
<!-- tab Yahoo -->
<p><strong>Yahoo</strong>   Yahoo  Questions是一个文本分类数据集。给定一个问题a和一个答案b，必须指定为十个可能类别中的一个。我们使用与AG’s News相同的patterns，但是我们将$P_{5}$中的“News”一词替换为“Question”。我们定义了一个verbalizer，它将类别1-10映射为“社会”、“科学”、“健康”、“教育”、“计算机”、“体育”、“商业”、“娱乐”、“关系”和“政治”。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="pattern-3"><p><strong>MNLI</strong>   MNLI数据集由文本对x  = (a，b)组成。任务是找出a是否蕴含着b (0)，a和b是否互相矛盾(1)，或者不矛盾(2)。我们定义</p>
<p>$P<em>{1}(x)$ = “a”? || </em> <em> </em> _,”b”</p>
<p>$P<em>{2}(x)$ = a? || </em> <em> </em> _ ,b</p>
<p>考虑两种不同的verbalizers $v<em>{1}$和$v</em>{2}$：</p>
<p>v1(0) = Wrong        v1(1) = Right     v1(2) = Maybe   </p>
<p>v2(0) = No        v2(1) = Yes    v2(2) = Maybe</p>
<p>将这两种patterns与这两种动verbalizers结合起来，总共会产生4个PVPs。</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div><div class="tab-item-content" id="pattern-4"><p><strong>X-Stance</strong>   x-stance数据集(Vamvas and Sennrich，2020)是一个多语言检测数据集，有德语、法语和意大利语的样本。每个样本x =  (a，b)由一个关于某个政治问题的问题a和一个评论b组成；任务是确定b的作者是否支持这个政治问题，支持为(0),不支持为(1)。使用两种简单的模式：</p>
<p>$P<em>{1}(x) = “a”||\ </em>{——}.\ “b”$</p>
<p>$P<em>{2}(x) = a\ ||\ </em>{——}.\ b$</p>
<p>定义了一个英文verbalizer $v<em>{En}$，把0映射为“Yes”，把1映射为“No”；定义了一个法语verbalizer  $v</em>{Fr}$，把0映射为“Oui”，把1映射为“Non”</p><button type="button" class="tab-to-top" aria-label="scroll to top"><i class="fas fa-arrow-up"></i></button></div></div></div>
<h4 id="Results"><a href="#Results" class="headerlink" title="Results"></a>Results</h4><h5 id="English-Datasets"><a href="#English-Datasets" class="headerlink" title="English Datasets"></a>English Datasets</h5><p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_3.png" alt="FSL18_3"></p>
<details class="folding-tag" ><summary> 表1，给定五种不同训练集大小，RoBERTa（large）的平均准确度和标准偏差 </summary>
              <div class='content'>
              <p>m:matched/ mm: mismatched　　</p><p>表1显示了英语文本分类和语言理解任务的结果；展示了三次训练的平均准确度和标准差。第1-2行(L1-L2)显示了无监督的性能，即没有<em>any training</em>的单个PVP；给出了所有PVP的平均结果(平均值)和在测试集上最有效的PVP的结果(最大值)。两行之间的巨大差异突出一个事实的重要性，即如果不查看测试集，就无法评估哪些PVP表现良好。zero-shot iPET在所有数据集上都明显优于无监督基线(L3  vs L1)；在AG’s News上，它甚至比标准的监督训练(L3 vs  L13)表现更好。仅用10个训练样本，标准的监督学习效果很差(L4)。相比之下，PET(L5)比完全无监督基线(L1-L2)表现更好；使用iPET  (L6)训练多代PET会带来持续的改进。由于增加了训练集的大小，PET和iPET的性能增益变得更小，但是对于50和100个样本，PET继续显著优于标准监督训练(L8 vs L7，L11 vs L10)，iPET  (L9，L12)进一步提升了性能。对于$|\mathcal T| = 1000$，PET在AG’s上的性能没有优势，但仍能提高所有其他任务的精度(L14 vs L13)。</p>
              </div>
            </details>
<h5 id="Comparison-with-SotA-state-of-the-art"><a href="#Comparison-with-SotA-state-of-the-art" class="headerlink" title="Comparison with SotA(state-of-the-art)"></a>Comparison with SotA(state-of-the-art)</h5><p>将PET与UDA和MixText进行了比较，这两种方法是NLP中基于数据增强的两种最先进的半监督学习方法。PET要求一个任务可以用patterns来表达，而UDA和MixText都使用backtranslation，因此需要成千上万个标记的样本来训练机器翻译模型。我们使用RoBERTa(base)进行比较，MixText包含一个12层的Transformer结构。</p>
<p>　　Xie et al.(2020)和Chen et al,(2020)都使用大型开发集来优化训练步骤的数量。相反，我们直接在测试集上尝试这两种方法，并且只报告获得的最佳结果。尽管如此，表2显示PET和iPET在所有任务中都大大优于这两种方法，清楚地展示了以PVPs的形式整合人类知识的好处。</p>
<p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_4.png" alt="FSL18_4"></p>
<h5 id="X-Stance"><a href="#X-Stance" class="headerlink" title="X-Stance"></a>X-Stance</h5><p>在X-Stance上进行了评估，来研究：</p>
<ol>
<li>是否对其他语言有效</li>
<li>训练集具有中等大小的时候，是否能有改进</li>
</ol>
<p>　　与Vamvas  and Senrich(2020)相比，我们不对dev执行任何超参数优化，而是使用更短的最大序列长度(256 vs 512)来加快训练和评估。</p>
<p>　　为了研究在<strong>有大量样本的情况下PET的性能</strong>，考虑了1000、2000和4000的训练集大小；对于这些配置中的每一种，分别微调French和German的模型，以便对训练数据进行更直接的下采样。此外，在整个法语和德语训练集上训练模型。在这种情况下，没有任何额外的未标记数据，因此只需设置$\mathcal D = \mathcal T$。对于French模型，使用$V<em>{En}$和$v</em>{Fr}$作为verbalizers，对于German模型，使用$v<em>{En}$和$v</em>{De}$。最后还研究了使用$v<em>{En}$、$v</em>{Fr}$、$v_{De}$在France和German数据集上联合训练的模型的性能。</p>
<p>　　结果如表3所示，在Vamvas  and Sennrich  (2020)之后，报告了标签0和1的F1分数的宏观平均值，在三次运行上取平均值。对于Italian(列“It”)，由于没有意大利语训练样本，报告了German和France模型的平均zero-shot跨语言性能。结果表明，即使在一千多个样本上进行训练，PET也能给所有语言带来巨大的改进；它还大大提高了zero-shot跨语言性能。</p>
<p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_5.png" alt="FSL18_5"></p>
<h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><h4 id="Combining-PVPs-1"><a href="#Combining-PVPs-1" class="headerlink" title="Combining PVPs"></a>Combining PVPs</h4><p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_6.png" alt="FSL18_6"></p>
<p>表4：基于单个PVP的模型的最小和最大精度，以及带和不带知识蒸馏的PET。</p>
<p>首先研究PET是否能够应对某些PVPs表现比其他PVPs差得多的情况。对于$|\mathcal T| = 10$，表4将PET的性能与微调后的最佳patterns和最差patterns的性能进行了比较；还包括在没有知识蒸馏的情况下，使用单个PVP对应的PET模型的集合得到的结果。即使经过微调，最佳模式和最差模式之间的差距仍然很大，尤其是对Yelp来说。然而，PET不仅能够弥补这一点，而且甚至比在所有任务中只使用性能最好的模式更能提高准确性。蒸馏给PET模型集合带来持续的改进;此外，它显著地减小了最终分类器的大小。uniform和 weighted PET之间没有明显的区别。</p>
<h4 id="Auxiliary-Language-Modeling"><a href="#Auxiliary-Language-Modeling" class="headerlink" title="Auxiliary Language Modeling"></a>Auxiliary Language Modeling</h4><p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_7.png" alt="FSL18_7"></p>
<p>图3：在训练期间加入语言建模损失$L_{MLM}$后，PET的精度得到提升（随着数据的增多，精度提升越来越小，也就是说数据越多，语言建模就越不重要）</p>
<p>分析了辅助语言建模任务对PET性能的影响。图3显示了为四种训练集添加语言建模任务后的性能改进。<strong>可以看到，当只在10个样本上训练时，辅助任务是非常有价值的。数据越多，它就越不重要，有时甚至会导致性能下降</strong>。只有在MNLI中，语言建模才能一直提供帮助。</p>
<h4 id="Iterative-PET"><a href="#Iterative-PET" class="headerlink" title="Iterative PET"></a>Iterative PET</h4><p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_8.png" alt="FSL18_8"></p>
<p>图4:zero-shot设置下iPET每一代模型的平均精度。跳过第二代和第三代时，AG‘s News和Yahoo的准确性用虚线表示。</p>
<hr>
<p>　　为了检查iPET是否能够改进PET模型，图4显示了zero-shot设置下all generations of models 的平均性能。每个额外的迭代确实进一步提高了PET集合的性能。</p>
<p>　　另一个问题是，通过快速增加（不是逐步增加）训练集的大小，是否可以在更少的迭代中获得较好的结果。为了回答这个问题，跳过了AG’s News和Yahoo数据集上的第2代和第3代PET，对于这两个任务，直接让$\mathcal M^{1}$为$\mathcal M^{4}$注释$10 \cdot 5^{4}$个样本。如图4中虚线所示，很明显导致了更糟糕的性能，<strong>突出显示了逐步增加训练集大小的重要性</strong>。<strong>我们推测这是因为过早地注释太多的样本会导致错误标记的训练样本比例很大（初始标记数据很少，所以初代PET模型精度不是很好，直接用它注释大量未标记样本，错误标记的概率很大。）</strong>。</p>
<h4 id="In-Domain-Pretraining"><a href="#In-Domain-Pretraining" class="headerlink" title="In-Domain Pretraining"></a>In-Domain Pretraining</h4><p><img src= "https://npm.elemecdn.com/gxy-assets/blogbuild/loading.gif" data-lazy-src="https://npm.elemecdn.com/gxy-assets/blogimg/FSL18_9.png" alt="FSL18_9"></p>
<p>图5：带有和不带有预训练(PT)的监督学习(sup)以及PET的精度</p>
<p>　　与监督基线不同，PET利用了额外的未标记数据集$\mathcal D$。因此，一些PET的性能超过监督基线的原因可能是因为额外的in-domain数据的影响。</p>
<p>　　为了验证这一假设，简单地进一步对in-domain数据进行RoBERTa预处理，这是一种提高文本分类准确性的常见技术。由于语言模型预处理很耗费GPU，只对Yelp数据集进行预处理。图5显示了有和没有这种内部预处理的监督学习和PET的结果。虽然预处理确实提高了监督训练的准确性，但监督模型的性能仍然明显不如PET，这<strong>表明我们方法的成功不仅仅是由于使用了额外的未标记数据</strong>。有趣的是，<strong>in-domain预处理对PET也有帮助，这表明PET以一种明显不同于standard masked language model pretraining的方式对未标记的数据加以利用</strong>。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><ul>
<li>向预训练的语言模型提供task description可以与标准的监督训练相结合。</li>
<li>提出PET，包括定义成对的完形填空问题patterns和verbalizers，帮助利用预训练语言模型中的知识，以便进行下游任务。</li>
<li>为所有 pattern-verbalizer pairs微调模型，并使用它们来创建大型注释数据集，在此基础上可以训练标准分类器。当初始训练数据量有限时PET比标准监督训练和强化半监督方法有很大的改进。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">郭新宇</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://gxystruggle.top/posts/FSL18/">https://gxystruggle.top/posts/FSL18/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://gxystruggle.top" target="_blank">Guo Xinyu's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%F0%9F%8C%8CMachine-Learning/">🌌Machine Learning</a><a class="post-meta__tags" href="/tags/%F0%9F%AA%90Meta-learning/">🪐Meta-learning</a><a class="post-meta__tags" href="/tags/%F0%9F%93%9DText-Classification/">📝Text Classification</a></div><div class="post_share"><div class="social-share" data-image="https://npm.elemecdn.com/gxy-assets/backandcover/34.jpg" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://npm.elemecdn.com/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://npm.elemecdn.com/social-share.js/dist/js/social-share.min.js" defer></script></div></div><link rel="stylesheet" href="https://npm.elemecdn.com/gxy-assets/jsandcss/coin.css" media="defer" onload="this.media='all'"/><div class="post-reward"><button class="tip-button reward-button"><span class="tip-button__text">好活儿，当赏！💰</span><div class="coin-wrapper"><div class="coin"><div class="coin__middle"></div><div class="coin__back"></div><div class="coin__front"></div></div></div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://npm.elemecdn.com/gxy-assets/blogbuild/wechat.png" target="_blank"><img class="post-qr-code-img" src="https://npm.elemecdn.com/gxy-assets/blogbuild/wechat.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://npm.elemecdn.com/gxy-assets/blogbuild/zhifubao.png" target="_blank"><img class="post-qr-code-img" src="https://npm.elemecdn.com/gxy-assets/blogbuild/zhifubao.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></button></div><audio id="coinAudio" src="https://npm.elemecdn.com/akilar-candyassets@1.0.16/audio/coin.mp3"></audio><script defer="defer" src="https://npm.elemecdn.com/gxy-assets/jsandcss/coin.js"></script><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/FSL19/"><img class="prev-cover" src="https://npm.elemecdn.com/gxy-assets/backandcover/35.jpg" onerror="onerror=null;src='https://npm.elemecdn.com/gxy-assets/blogbuild/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners</div></div></a></div><div class="next-post pull-right"><a href="/posts/FSL17/"><img class="next-cover" src="https://npm.elemecdn.com/gxy-assets/backandcover/33.jpg" onerror="onerror=null;src='https://npm.elemecdn.com/gxy-assets/blogbuild/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Boosting Few-Shot Learning With Adaptive Margin Loss</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div id="comment-switch"><span class="first-comment">Twikoo</span><span class="switch-btn"></span><span class="second-comment">Gitalk</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://npm.elemecdn.com/gxy-assets/blogbuild/%E5%A4%B4%E5%83%8F.jpg" onerror="this.onerror=null;this.src='https://npm.elemecdn.com/gxy-assets/blogbuild/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">郭新宇</div><div class="author-info__description">牧羊少年</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">35</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">19</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/guoxinyu1998" target="_blank" title="Github"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github1"></use></svg></a><a class="social-icon" href="mailto:984189011x@qq.com" target="_blank" title="Email"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-loveletter"></use></svg></a><a class="social-icon" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=984189011&amp;website=www.oicqzone.com" target="_blank" title="QQ"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-QQ"></use></svg></a><a class="social-icon" href="https://weibo.com/6079019133/profile?rightmod=1&amp;wvr=6&amp;mod=personinfo" target="_blank" title="Weibo"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weibo1"></use></svg></a><a class="social-icon" href="https://npm.elemecdn.com/gxy-assets/blogbuild/微信名片.jpg" target="_blank" title="Wechat"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-weixin"></use></svg></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pattern-Exploiting-Training"><span class="toc-number">3.</span> <span class="toc-text">Pattern-Exploiting Training</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#PVP-Training-and-Inference"><span class="toc-number">3.1.</span> <span class="toc-text">PVP Training and Inference</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BE%85%E5%8A%A9%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1"><span class="toc-number">3.2.</span> <span class="toc-text">辅助语言建模</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Combining-PVPs"><span class="toc-number">3.3.</span> <span class="toc-text">Combining PVPs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Iterative-PET-iPET"><span class="toc-number">3.4.</span> <span class="toc-text">Iterative PET (iPET)</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Experiments"><span class="toc-number">4.</span> <span class="toc-text">Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Patterns"><span class="toc-number">4.1.</span> <span class="toc-text">Patterns</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Results"><span class="toc-number">4.2.</span> <span class="toc-text">Results</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#English-Datasets"><span class="toc-number">4.2.1.</span> <span class="toc-text">English Datasets</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Comparison-with-SotA-state-of-the-art"><span class="toc-number">4.2.2.</span> <span class="toc-text">Comparison with SotA(state-of-the-art)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#X-Stance"><span class="toc-number">4.2.3.</span> <span class="toc-text">X-Stance</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Analysis"><span class="toc-number">5.</span> <span class="toc-text">Analysis</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Combining-PVPs-1"><span class="toc-number">5.1.</span> <span class="toc-text">Combining PVPs</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Auxiliary-Language-Modeling"><span class="toc-number">5.2.</span> <span class="toc-text">Auxiliary Language Modeling</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Iterative-PET"><span class="toc-number">5.3.</span> <span class="toc-text">Iterative PET</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#In-Domain-Pretraining"><span class="toc-number">5.4.</span> <span class="toc-text">In-Domain Pretraining</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">6.</span> <span class="toc-text">Conclusion</span></a></li></ol></div></div><div class="card-widget card-recommend-post"><div class="item-headline"><i class="fas fa-dharmachakra"></i><span>相关推荐</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL12/" title="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/17.jpg" alt="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION"></a><div class="content"><a class="title" href="/posts/FSL12/" title="ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION">ATTENTIVE TASK-AGNOSTIC META-LEARNING FOR FEW-SHOT TEXT CLASSIFICATION</a><time datetime="2022-03-19" title="发表于 2022-03-19">2022-03-19</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL10/" title="Dynamic Memory Induction Networks for Few-Shot Text Classification"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/15.jpg" alt="Dynamic Memory Induction Networks for Few-Shot Text Classification"></a><div class="content"><a class="title" href="/posts/FSL10/" title="Dynamic Memory Induction Networks for Few-Shot Text Classification">Dynamic Memory Induction Networks for Few-Shot Text Classification</a><time datetime="2022-03-05" title="发表于 2022-03-05">2022-03-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL14/" title="Few-Shot Learning with Global Class Representations"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/27.jpg" alt="Few-Shot Learning with Global Class Representations"></a><div class="content"><a class="title" href="/posts/FSL14/" title="Few-Shot Learning with Global Class Representations">Few-Shot Learning with Global Class Representations</a><time datetime="2022-03-27" title="发表于 2022-03-27">2022-03-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL2/" title="Few-shot learning for short text classification"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/2.jpg" alt="Few-shot learning for short text classification"></a><div class="content"><a class="title" href="/posts/FSL2/" title="Few-shot learning for short text classification">Few-shot learning for short text classification</a><time datetime="2022-01-08" title="发表于 2022-01-08">2022-01-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL8att2/" title="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/13.jpg" alt="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification"></a><div class="content"><a class="title" href="/posts/FSL8att2/" title="Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification">Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification</a><time datetime="2022-02-23" title="发表于 2022-02-23">2022-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/posts/FSL6/" title="Diverse few-shot Text classification with multiple metrics"><img src="https://npm.elemecdn.com/gxy-assets/backandcover/7.jpg" alt="Diverse few-shot Text classification with multiple metrics"></a><div class="content"><a class="title" href="/posts/FSL6/" title="Diverse few-shot Text classification with multiple metrics">Diverse few-shot Text classification with multiple metrics</a><time datetime="2022-02-12" title="发表于 2022-02-12">2022-02-12</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022  <i id="heartbeat" class="fa fas fa-heartbeat"></i> 郭新宇</div></div><head><link rel="stylesheet" href="https://npm.elemecdn.com/gxy-assets/jsandcss/heartbeat.min.css"></head></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><button id="to_comment" type="button" title="直达评论" onclick="FixedCommentBtn();"><i class="fas fa-comments"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">本地搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://npm.elemecdn.com/medium-zoom/dist/medium-zoom.min.js"></script><script src="https://npm.elemecdn.com/instant.page/instantpage.min.js" type="module"></script><script src="https://npm.elemecdn.com/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://npm.elemecdn.com/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://npm.elemecdn.com/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><script src="/js/search/local-search.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://npm.elemecdn.com/katex@latest/dist/katex.min.css"><script src="https://npm.elemecdn.com/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://npm.elemecdn.com/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>(()=>{
  const init = () => {
    twikoo.init(Object.assign({
      el: '#twikoo-wrap',
      envId: 'https://twikoo-one-jade.vercel.app/',
      region: 'ap-baoding',
      onCommentLoaded: function () {
        btf.loadLightbox(document.querySelectorAll('#twikoo .tk-content img:not(.vemoji)'))
      }
    }, null))
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo-one-jade.vercel.app/',
      region: 'ap-baoding',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      document.getElementById('twikoo-count').innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const runFn = () => {
    init()
    GLOBAL_CONFIG_SITE.isPost && getCount()
  }

  const loadTwikoo = () => {
    if (typeof twikoo === 'object') {
      setTimeout(runFn,0)
      return
    } 
    getScript('https://npm.elemecdn.com/twikoo/dist/twikoo.all.min.js').then(runFn)
  }

  if ('Twikoo' === 'Twikoo' || !true) {
    if (true) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo()
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script><script>function addGitalkSource () {
  const ele = document.createElement('link')
  ele.rel = 'stylesheet'
  ele.href= 'https://npm.elemecdn.com/gitalk/dist/gitalk.min.css'
  document.getElementsByTagName('head')[0].appendChild(ele)
}

function loadGitalk () {
  function initGitalk () {
    var gitalk = new Gitalk(Object.assign({
      clientID: 'd72c334ea626f70aa6a5',
      clientSecret: 'd9b9e251acfdf70e336930214bdffe83f697e504',
      repo: 'gxystruggle_gitalk',
      owner: 'guoxinyu1998',
      admin: ['guoxinyu1998'],
      id: 'eefd39b0a1f5621a4254415c414427de',
      updateCountCallback: commentCount
    },null))

    gitalk.render('gitalk-container')
  }

  if (typeof Gitalk === 'function') initGitalk()
  else {
    addGitalkSource()
    getScript('https://npm.elemecdn.com/gitalk@latest/dist/gitalk.min.js').then(initGitalk)
  }
}

function commentCount(n){
  let isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
  if (isCommentCount) {
    isCommentCount.innerHTML= n
  }
}

if ('Twikoo' === 'Gitalk' || !true) {
  if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
  else loadGitalk()
} else {
  function loadOtherComment () {
    loadGitalk()
  }
}</script></div><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getComment = () => {
    const runTwikoo = () => {
      twikoo.getRecentComments({
        envId: 'https://twikoo-one-jade.vercel.app/',
        region: 'ap-baoding',
        pageSize: 6,
        includeReply: true
      }).then(function (res) {
        const twikooArray = res.map(e => {
          return {
            'content': changeContent(e.comment),
            'avatar': e.avatar,
            'nick': e.nick,
            'url': e.url + '#' + e.id,
            'date': new Date(e.created).toISOString()
          }
        })

        saveToLocal.set('twikoo-newest-comments', JSON.stringify(twikooArray), 10/(60*24))
        generateHtml(twikooArray)
      }).catch(function (err) {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.innerHTML= "无法获取评论，请确认相关配置是否正确"
      })
    }

    if (typeof twikoo === 'object') {
      runTwikoo()
    } else {
      getScript('https://npm.elemecdn.com/twikoo/dist/twikoo.all.min.js').then(runTwikoo)
    }
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }
        
        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${btf.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom.innerHTML= result
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('twikoo-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script src="https://npm.elemecdn.com/gxy-assets/jsandcss/fairyDustCursor.js"></script><script defer src="https://npm.elemecdn.com/gxy-assets/jsandcss/live2d_autoload.min.js"></script><div class="aplayer no-destroy" data-id="2698841554" data-server="netease" data-type="playlist" data-fixed="true" data-mini="true" data-listFolded="false" data-order="list" data-lrctype="1" data-preload="none" data-autoplay="false" muted></div><script async src="https://npm.elemecdn.com/gxy-assets/jsandcss/dttitle.js"></script><script async src="//at.alicdn.com/t/font_3185678_5n830b5k2dm.js"></script><script data-pjax defer src="https://npm.elemecdn.com/gxy-assets/jsandcss/fixed_comment.js"></script><script src="https://npm.elemecdn.com/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = true;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-heart" src="https://npm.elemecdn.com/butterfly-extsrc@1/dist/click-heart.min.js" async="async" mobile="true"></script><script src="//code.tidio.co/m1tn6ajp5sxcxrsywtbtodb6ercpapyk.js" async="async"></script><script>function onTidioChatApiReady() {
  window.tidioChatApi.hide();
  window.tidioChatApi.on("close", function() {
    window.tidioChatApi.hide();
  });
}
if (window.tidioChatApi) {
  window.tidioChatApi.on("ready", onTidioChatApiReady);
} else {
  document.addEventListener("tidioChat-ready", onTidioChatApiReady);
}

var chatBtnFn = () => {
  document.getElementById("chat_btn").addEventListener("click", function(){
    window.tidioChatApi.show();
    window.tidioChatApi.open();
  });
}
chatBtnFn()
</script><link rel="stylesheet" href="https://npm.elemecdn.com/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://npm.elemecdn.com/aplayer/dist/APlayer.min.js"></script><script src="https://npm.elemecdn.com/gxy-assets/jsandcss/Meting.min.js"></script><script src="https://npm.elemecdn.com/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show","#fixedcard-dashboard","#web_bg",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax], .pjax-reload script').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><div class="app-refresh" id="app-refresh" style="position: fixed;top: -2.2rem;left: 0;right: 0;z-index: 99999;padding: 0 1rem;font-size: 15px;height: 2.2rem;transition: all 0.3s ease;"><div class="app-refresh-wrap" style=" display: flex;color: #fff;height: 100%;align-items: center;justify-content: center;"><label>✨ 郭新宇的魔法屋上新啦！ 👉</label><a href="javascript:void(0)" onclick="location.reload()"><span style="color: #fff;text-decoration: underline;cursor: pointer;">🍭查看新品🍬</span></a></div></div><script>if ('serviceWorker' in navigator) {
if (navigator.serviceWorker.controller) {
navigator.serviceWorker.addEventListener('controllerchange', function() {
showNotification()
})
}
window.addEventListener('load', function() {
navigator.serviceWorker.register('/sw.js')
})
}
function showNotification() {
if (GLOBAL_CONFIG.Snackbar) {
var snackbarBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
GLOBAL_CONFIG.Snackbar.bgLight :
GLOBAL_CONFIG.Snackbar.bgDark
var snackbarPos = GLOBAL_CONFIG.Snackbar.position
Snackbar.show({
text: '✨ 郭新宇的魔法屋上新啦！ 👉',
backgroundColor: snackbarBg,
duration: 500000,
pos: snackbarPos,
actionText: '🍭查看新品🍬',
actionTextColor: '#fff',
onActionClick: function(e) {
location.reload()
},
})
} else {
var showBg =
document.documentElement.getAttribute('data-theme') === 'light' ?
'#49b1f5' :
'#1f1f1f'
var cssText = `top: 0; background: ${showBg};`
document.getElementById('app-refresh').style.cssText = cssText
}
}</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_injector_config();
  }
  </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax src="https://npm.elemecdn.com/hexo-butterfly-clock/lib/clock.min.js"></script><div class="js-pjax"><script async="async">var arr = document.getElementsByClassName('recent-post-item');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '1s');
    arr[i].setAttribute('data-wow-delay', '0.5s');
    arr[i].setAttribute('data-wow-offset', '100');
    arr[i].setAttribute('data-wow-iteration', '1');
  }</script><script async="async">var arr = document.getElementsByClassName('card-widget');
for(var i = 0;i<arr.length;i++){
    arr[i].classList.add('wow');
    arr[i].classList.add('animate__zoomIn');
    arr[i].setAttribute('data-wow-duration', '');
    arr[i].setAttribute('data-wow-delay', '');
    arr[i].setAttribute('data-wow-offset', '');
    arr[i].setAttribute('data-wow-iteration', '');
  }</script></div><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow.min.js"></script><script defer src="https://unpkg.zhimg.com/hexo-butterfly-wowjs/lib/wow_init.js"></script><script data-pjax>
  function butterfly_footer_beautify_injector_config(){
    var parent_div_git = document.getElementById('footer-wrap');
    var item_html = '<div id="workboard"></div><div id="ghbdages" style="overflow:hidden;max-height:90px;height:auto;text-align:center;margin-top:10px"><div class="swiper-wrapper"><div class="swiper-slide"><a class="github-badge" target="_blank" href="http://beian.miit.gov.cn/" style="margin-inline:5px" title="本站已经成功在工信部备案"><img src="https://img.shields.io/badge/%E5%86%80ICP%E5%A4%87-2022002305%E5%8F%B7-e1d492?style=plastic&amp;logo=data:image/png;base64,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" alt=""/></a><a class="github-badge" target="_blank" href="https://hexo.io/" style="margin-inline:5px" title="博客框架为Hexo_v6.0.0"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=plastic&amp;logo=hexo" alt=""/></a><a class="github-badge" target="_blank" href="https://butterfly.js.org/" style="margin-inline:5px" title="主题版本Butterfly_v4.0.1"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=plastic&amp;logo=bitdefender" alt=""/></a></div><div class="swiper-slide"><a class="github-badge" target="_blank" href="https://github.com/" style="margin-inline:5px" title="本站资源托管在Github"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=plastic&amp;logo=GitHub" alt=""/></a><a class="github-badge" target="_blank" href="https://vercel.com/" style="margin-inline:5px" title="本站由Vercel提供加速服务"><img src="https://img.shields.io/badge/Hosted-Vercel-brightgreen?style=plastic&amp;logo=Vercel" alt=""/></a><a class="github-badge" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" style="margin-inline:5px" title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&amp;logo=Claris" alt=""/></a></div></div></div><style>a.github-badge:hover:before {display:none}</style>';
    console.log('已挂载butterfly_footer_beautify')
    parent_div_git.insertAdjacentHTML("beforeend",item_html)
    }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_footer_beautify_injector_config();
  }
  else if (epage === cpage){
    butterfly_footer_beautify_injector_config();
  }
  </script><script async src="/js/runtime.js"></script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-footer-beautify/lib/swiperbdage_init.min.js"></script><script data-pjax src="https://npm.elemecdn.com/hexo-filter-gitcalendar/lib/gitcalendar.js"></script><script data-pjax>
  function gitcalendar_injector_config(){
      var parent_div_git = document.getElementById('recent-posts');
      var item_html = '<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><style>#git_container{min-height: 280px}@media screen and (max-width:650px) {#git_container{min-height: 0px}}</style><div id="git_loading" style="width:10%;height:100%;margin:0 auto;display: block;"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animatetransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animatetransform></path></svg><style>#git_container{display: none;}</style></div><div id="git_container"></div></div>';
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
      console.log('已挂载gitcalendar')
      }

    if( document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
        gitcalendar_injector_config()
        GitCalendarInit("https://blog-calendaler.vercel.app/api?guoxinyu1998",['#e4dfd7', '#f9f4dc', '#f7e8aa', '#f7e8aa', '#f8df72', '#fcd217', '#fcc515', '#f28e16', '#fb8b05', '#d85916', '#f43e06'],'guoxinyu1998')
    }
  </script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/11/" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/gxy-assets/backandcover/25.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-25</span><a class="blog-slider__title" href="posts/11/" alt="">C++感悟</a><div class="blog-slider__text">C++自学思路指南以及心得体会！</div><a class="blog-slider__button" href="posts/11/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/10/" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/gxy-assets/backandcover/22.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-24</span><a class="blog-slider__title" href="posts/10/" alt="">Few-shot Learning</a><div class="blog-slider__text">FSL相关论文以及个人理解！</div><a class="blog-slider__button" href="posts/10/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/ynzz1/" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/gxy-assets/backandcover/23.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-24</span><a class="blog-slider__title" href="posts/ynzz1/" alt="">20年老中医，专治各种疑难杂症</a><div class="blog-slider__text">记录一下学习生活中遇到的各种稀奇古怪的难题！</div><a class="blog-slider__button" href="posts/ynzz1/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/6/" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/gxy-assets/backandcover/19.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-03-22</span><a class="blog-slider__title" href="posts/6/" alt="">如何写出令人赏心悦目的博客</a><div class="blog-slider__text">markdown命令，latex数学符号，博客中的图片问题，外挂标签的使用……想要写出清晰明了，美观大气的博客看这一篇就够了！</div><a class="blog-slider__button" href="posts/6/" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="posts/1/" alt=""><img width="48" height="48" src="https://npm.elemecdn.com/gxy-assets/backandcover/8.jpg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-02-15</span><a class="blog-slider__title" href="posts/1/" alt="">Hexo和Butterfly那点事儿</a><div class="blog-slider__text">Hexo博客搭建、Butterfly主题美化以及个性化设置！</div><a class="blog-slider__button" href="posts/1/" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><script async src="//at.alicdn.com/t/font_2032782_8d5kxvn09md.js"></script><!-- hexo injector body_end end --></body></html>